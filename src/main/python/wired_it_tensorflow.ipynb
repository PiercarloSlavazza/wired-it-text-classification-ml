{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embedding_dim = 200\n",
    "corpus_base_dir = os.path.join('..', '..', '..', 'corpora', 'wired_it_20190821')\n",
    "\n",
    "vocab_size = 10000\n",
    "max_length = 1000\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "num_epochs = 100\n",
    "\n",
    "training_dir = os.path.join(corpus_base_dir, 'training')\n",
    "test_dir = os.path.join(corpus_base_dir, 'test')\n",
    "classes = ['attualit_','attualit__ambiente','attualit__media','attualit__politica','attualit__tech','economia_business','economia_finanza','economia_lavoro','economia_startup','gadget_accessori','gadget_audio_e_tv','gadget_computer','gadget_elettrodomestici','gadget_foto_e_video','gadget_motori','gadget_outdoor','gadget_videogiochi','internet_regole','internet_social_network','internet_tlc','internet_web','lifestyle_design','lifestyle_food','lifestyle_mobilit_','lifestyle_salute','lifestyle_viaggi','lol','mobile_app','mobile_smartphone','mobile_tablet','play_cinema','play_cultura','play_fumetti','play_libri','play_musica','play_tv','scienza','scienza_biotech','scienza_ecologia','scienza_lab','scienza_medicina','scienza_spazio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_text(file_path):\n",
    "  with open(file_path, 'r', encoding=\"utf8\") as file:\n",
    "    return file.read().replace('\\n', ' ')\n",
    "def list_text_files(folder):\n",
    "  return [os.path.join(folder, file_name) for file_name in os.listdir(folder) if file_name.endswith('.txt')]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_class_text_pairs = lambda folder: map(lambda classLabel: map(lambda file_name: (classLabel, read_file_to_text(file_name)), list_text_files(os.path.join(folder, classLabel))) , classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_classes, training_texts = zip(*flatten(list(load_class_text_pairs(training_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes, test_texts = zip(*flatten(list(load_class_text_pairs(test_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(training_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(training_texts)\n",
    "training_padded = pad_sequences(training_sequences, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the '_' because class names features '_' as separators (and they need NOT to be split, thay must be a unique token)\n",
    "classes_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "classes_tokenizer.fit_on_texts(classes)\n",
    "\n",
    "training_classes_seq = np.array(classes_tokenizer.texts_to_sequences(training_classes))\n",
    "test_classes_seq = np.array(classes_tokenizer.texts_to_sequences(test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attualit_': 1, 'attualit__ambiente': 2, 'attualit__media': 3, 'attualit__politica': 4, 'attualit__tech': 5, 'economia_business': 6, 'economia_finanza': 7, 'economia_lavoro': 8, 'economia_startup': 9, 'gadget_accessori': 10, 'gadget_audio_e_tv': 11, 'gadget_computer': 12, 'gadget_elettrodomestici': 13, 'gadget_foto_e_video': 14, 'gadget_motori': 15, 'gadget_outdoor': 16, 'gadget_videogiochi': 17, 'internet_regole': 18, 'internet_social_network': 19, 'internet_tlc': 20, 'internet_web': 21, 'lifestyle_design': 22, 'lifestyle_food': 23, 'lifestyle_mobilit_': 24, 'lifestyle_salute': 25, 'lifestyle_viaggi': 26, 'lol': 27, 'mobile_app': 28, 'mobile_smartphone': 29, 'mobile_tablet': 30, 'play_cinema': 31, 'play_cultura': 32, 'play_fumetti': 33, 'play_libri': 34, 'play_musica': 35, 'play_tv': 36, 'scienza': 37, 'scienza_biotech': 38, 'scienza_ecologia': 39, 'scienza_lab': 40, 'scienza_medicina': 41, 'scienza_spazio': 42}\n"
     ]
    }
   ],
   "source": [
    "training_classes_encoded = [class_encoded[0] for class_encoded in training_classes_seq]\n",
    "classes_word_index = classes_tokenizer.word_index\n",
    "print(classes_word_index)\n",
    "classes_by_index = dict([(index, key) for (key, index) in classes_word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    #tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    #tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(classes) + 1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                8643      \n",
      "=================================================================\n",
      "Total params: 2,008,643\n",
      "Trainable params: 2,008,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=[f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13351 samples, validate on 5709 samples\n",
      "Epoch 1/100\n",
      "13351/13351 - 4s - loss: 3.6803 - f1: 40.0775 - val_loss: 3.6124 - val_f1: 36.9009\n",
      "Epoch 2/100\n",
      "13351/13351 - 4s - loss: 3.5382 - f1: 36.3205 - val_loss: 3.4601 - val_f1: 35.1849\n",
      "Epoch 3/100\n",
      "13351/13351 - 4s - loss: 3.3067 - f1: 34.5056 - val_loss: 3.1946 - val_f1: 32.7956\n",
      "Epoch 4/100\n",
      "13351/13351 - 4s - loss: 3.0146 - f1: 31.0974 - val_loss: 2.9380 - val_f1: 29.4432\n",
      "Epoch 5/100\n",
      "13351/13351 - 4s - loss: 2.7483 - f1: 27.7662 - val_loss: 2.7105 - val_f1: 26.5041\n",
      "Epoch 6/100\n",
      "13351/13351 - 4s - loss: 2.5133 - f1: 24.8285 - val_loss: 2.5140 - val_f1: 24.0448\n",
      "Epoch 7/100\n",
      "13351/13351 - 4s - loss: 2.3079 - f1: 22.0826 - val_loss: 2.3501 - val_f1: 21.7033\n",
      "Epoch 8/100\n",
      "13351/13351 - 4s - loss: 2.1317 - f1: 19.7401 - val_loss: 2.2130 - val_f1: 19.5845\n",
      "Epoch 9/100\n",
      "13351/13351 - 4s - loss: 1.9805 - f1: 17.6849 - val_loss: 2.0967 - val_f1: 17.8867\n",
      "Epoch 10/100\n",
      "13351/13351 - 4s - loss: 1.8495 - f1: 15.8991 - val_loss: 2.0052 - val_f1: 16.1443\n",
      "Epoch 11/100\n",
      "13351/13351 - 4s - loss: 1.7353 - f1: 14.3964 - val_loss: 1.9278 - val_f1: 14.8040\n",
      "Epoch 12/100\n",
      "13351/13351 - 4s - loss: 1.6346 - f1: 13.1151 - val_loss: 1.8605 - val_f1: 13.8490\n",
      "Epoch 13/100\n",
      "13351/13351 - 4s - loss: 1.5443 - f1: 12.0873 - val_loss: 1.8088 - val_f1: 12.6756\n",
      "Epoch 14/100\n",
      "13351/13351 - 4s - loss: 1.4619 - f1: 11.1680 - val_loss: 1.7557 - val_f1: 12.1430\n",
      "Epoch 15/100\n",
      "13351/13351 - 4s - loss: 1.3863 - f1: 10.4021 - val_loss: 1.7190 - val_f1: 11.2318\n",
      "Epoch 16/100\n",
      "13351/13351 - 4s - loss: 1.3170 - f1: 9.6827 - val_loss: 1.6856 - val_f1: 10.8340\n",
      "Epoch 17/100\n",
      "13351/13351 - 4s - loss: 1.2511 - f1: 9.1182 - val_loss: 1.6513 - val_f1: 10.2027\n",
      "Epoch 18/100\n",
      "13351/13351 - 4s - loss: 1.1892 - f1: 8.5653 - val_loss: 1.6268 - val_f1: 9.6865\n",
      "Epoch 19/100\n",
      "13351/13351 - 4s - loss: 1.1313 - f1: 8.0679 - val_loss: 1.6024 - val_f1: 9.2904\n",
      "Epoch 20/100\n",
      "13351/13351 - 4s - loss: 1.0749 - f1: 7.6522 - val_loss: 1.5842 - val_f1: 8.8139\n",
      "Epoch 21/100\n",
      "13351/13351 - 4s - loss: 1.0224 - f1: 7.2484 - val_loss: 1.5644 - val_f1: 8.5220\n",
      "Epoch 22/100\n",
      "13351/13351 - 4s - loss: 0.9704 - f1: 6.8488 - val_loss: 1.5540 - val_f1: 8.1594\n",
      "Epoch 23/100\n",
      "13351/13351 - 4s - loss: 0.9215 - f1: 6.5279 - val_loss: 1.5363 - val_f1: 7.8889\n",
      "Epoch 24/100\n",
      "13351/13351 - 4s - loss: 0.8745 - f1: 6.2082 - val_loss: 1.5288 - val_f1: 7.6313\n",
      "Epoch 25/100\n",
      "13351/13351 - 4s - loss: 0.8293 - f1: 5.9237 - val_loss: 1.5177 - val_f1: 7.2543\n",
      "Epoch 26/100\n",
      "13351/13351 - 4s - loss: 0.7859 - f1: 5.6372 - val_loss: 1.5070 - val_f1: 6.9729\n",
      "Epoch 27/100\n",
      "13351/13351 - 4s - loss: 0.7434 - f1: 5.3773 - val_loss: 1.5067 - val_f1: 6.8475\n",
      "Epoch 28/100\n",
      "13351/13351 - 4s - loss: 0.7034 - f1: 5.1222 - val_loss: 1.5025 - val_f1: 6.6083\n",
      "Epoch 29/100\n",
      "13351/13351 - 4s - loss: 0.6642 - f1: 4.8912 - val_loss: 1.5017 - val_f1: 6.4496\n",
      "Epoch 30/100\n",
      "13351/13351 - 4s - loss: 0.6272 - f1: 4.6751 - val_loss: 1.5008 - val_f1: 6.1471\n",
      "Epoch 31/100\n",
      "13351/13351 - 4s - loss: 0.5923 - f1: 4.4471 - val_loss: 1.4929 - val_f1: 6.1305\n",
      "Epoch 32/100\n",
      "13351/13351 - 4s - loss: 0.5582 - f1: 4.2564 - val_loss: 1.4921 - val_f1: 5.8853\n",
      "Epoch 33/100\n",
      "13351/13351 - 4s - loss: 0.5244 - f1: 4.0745 - val_loss: 1.4980 - val_f1: 5.5983\n",
      "Epoch 34/100\n",
      "13351/13351 - 4s - loss: 0.4943 - f1: 3.8862 - val_loss: 1.4981 - val_f1: 5.5588\n",
      "Epoch 35/100\n",
      "13351/13351 - 4s - loss: 0.4638 - f1: 3.7281 - val_loss: 1.4985 - val_f1: 5.4502\n",
      "Epoch 36/100\n",
      "13351/13351 - 4s - loss: 0.4353 - f1: 3.5537 - val_loss: 1.5082 - val_f1: 5.2307\n",
      "Epoch 37/100\n",
      "13351/13351 - 4s - loss: 0.4087 - f1: 3.4029 - val_loss: 1.5131 - val_f1: 5.2082\n",
      "Epoch 38/100\n",
      "13351/13351 - 4s - loss: 0.3827 - f1: 3.2823 - val_loss: 1.5209 - val_f1: 5.0068\n",
      "Epoch 39/100\n",
      "13351/13351 - 4s - loss: 0.3590 - f1: 3.1364 - val_loss: 1.5236 - val_f1: 4.8973\n",
      "Epoch 40/100\n",
      "13351/13351 - 4s - loss: 0.3355 - f1: 3.0022 - val_loss: 1.5342 - val_f1: 4.7395\n",
      "Epoch 41/100\n",
      "13351/13351 - 4s - loss: 0.3130 - f1: 2.8797 - val_loss: 1.5456 - val_f1: 4.5694\n",
      "Epoch 42/100\n",
      "13351/13351 - 4s - loss: 0.2926 - f1: 2.7662 - val_loss: 1.5550 - val_f1: 4.5136\n",
      "Epoch 43/100\n",
      "13351/13351 - 4s - loss: 0.2725 - f1: 2.6491 - val_loss: 1.5731 - val_f1: 4.3250\n",
      "Epoch 44/100\n",
      "13351/13351 - 4s - loss: 0.2542 - f1: 2.5484 - val_loss: 1.5809 - val_f1: 4.3742\n",
      "Epoch 45/100\n",
      "13351/13351 - 4s - loss: 0.2373 - f1: 2.4664 - val_loss: 1.5867 - val_f1: 4.3360\n",
      "Epoch 46/100\n",
      "13351/13351 - 4s - loss: 0.2212 - f1: 2.3609 - val_loss: 1.6071 - val_f1: 4.1373\n",
      "Epoch 47/100\n",
      "13351/13351 - 4s - loss: 0.2049 - f1: 2.2629 - val_loss: 1.6195 - val_f1: 4.0628\n",
      "Epoch 48/100\n",
      "13351/13351 - 4s - loss: 0.1904 - f1: 2.1784 - val_loss: 1.6360 - val_f1: 3.9031\n",
      "Epoch 49/100\n",
      "13351/13351 - 4s - loss: 0.1767 - f1: 2.1024 - val_loss: 1.6492 - val_f1: 3.9309\n",
      "Epoch 50/100\n",
      "13351/13351 - 4s - loss: 0.1640 - f1: 2.0189 - val_loss: 1.6697 - val_f1: 3.7840\n",
      "Epoch 51/100\n",
      "13351/13351 - 4s - loss: 0.1525 - f1: 1.9610 - val_loss: 1.6856 - val_f1: 3.8193\n",
      "Epoch 52/100\n",
      "13351/13351 - 4s - loss: 0.1407 - f1: 1.8895 - val_loss: 1.6995 - val_f1: 3.6820\n",
      "Epoch 53/100\n",
      "13351/13351 - 4s - loss: 0.1305 - f1: 1.8198 - val_loss: 1.7135 - val_f1: 3.6412\n",
      "Epoch 54/100\n",
      "13351/13351 - 4s - loss: 0.1209 - f1: 1.7584 - val_loss: 1.7327 - val_f1: 3.5694\n",
      "Epoch 55/100\n",
      "13351/13351 - 4s - loss: 0.1122 - f1: 1.6967 - val_loss: 1.7537 - val_f1: 3.5031\n",
      "Epoch 56/100\n",
      "13351/13351 - 4s - loss: 0.1042 - f1: 1.6525 - val_loss: 1.7688 - val_f1: 3.3915\n",
      "Epoch 57/100\n",
      "13351/13351 - 4s - loss: 0.0963 - f1: 1.5953 - val_loss: 1.7897 - val_f1: 3.3456\n",
      "Epoch 58/100\n",
      "13351/13351 - 4s - loss: 0.0897 - f1: 1.5464 - val_loss: 1.8090 - val_f1: 3.3815\n",
      "Epoch 59/100\n",
      "13351/13351 - 4s - loss: 0.0833 - f1: 1.5054 - val_loss: 1.8276 - val_f1: 3.2963\n",
      "Epoch 60/100\n",
      "13351/13351 - 4s - loss: 0.0773 - f1: 1.4619 - val_loss: 1.8415 - val_f1: 3.2127\n",
      "Epoch 61/100\n",
      "13351/13351 - 4s - loss: 0.0720 - f1: 1.4216 - val_loss: 1.8745 - val_f1: 3.2207\n",
      "Epoch 62/100\n",
      "13351/13351 - 4s - loss: 0.0670 - f1: 1.3934 - val_loss: 1.8933 - val_f1: 3.1127\n",
      "Epoch 63/100\n",
      "13351/13351 - 4s - loss: 0.0629 - f1: 1.3499 - val_loss: 1.9061 - val_f1: 3.1069\n",
      "Epoch 64/100\n",
      "13351/13351 - 4s - loss: 0.0585 - f1: 1.3245 - val_loss: 1.9379 - val_f1: 3.0741\n",
      "Epoch 65/100\n",
      "13351/13351 - 4s - loss: 0.0548 - f1: 1.2938 - val_loss: 1.9520 - val_f1: 3.0050\n",
      "Epoch 66/100\n",
      "13351/13351 - 4s - loss: 0.0512 - f1: 1.2716 - val_loss: 1.9746 - val_f1: 2.9728\n",
      "Epoch 67/100\n",
      "13351/13351 - 4s - loss: 0.0486 - f1: 1.2424 - val_loss: 2.0073 - val_f1: 2.9837\n",
      "Epoch 68/100\n",
      "13351/13351 - 4s - loss: 0.0457 - f1: 1.2273 - val_loss: 2.0217 - val_f1: 2.8611\n",
      "Epoch 69/100\n",
      "13351/13351 - 4s - loss: 0.0429 - f1: 1.2026 - val_loss: 2.0364 - val_f1: 2.8957\n",
      "Epoch 70/100\n",
      "13351/13351 - 4s - loss: 0.0410 - f1: 1.1868 - val_loss: 2.0613 - val_f1: 2.8784\n",
      "Epoch 71/100\n",
      "13351/13351 - 4s - loss: 0.0384 - f1: 1.1731 - val_loss: 2.0775 - val_f1: 2.7312\n",
      "Epoch 72/100\n",
      "13351/13351 - 4s - loss: 0.0373 - f1: 1.1606 - val_loss: 2.0999 - val_f1: 2.7673\n",
      "Epoch 73/100\n",
      "13351/13351 - 4s - loss: 0.0352 - f1: 1.1476 - val_loss: 2.1385 - val_f1: 2.6384\n",
      "Epoch 74/100\n",
      "13351/13351 - 4s - loss: 0.0343 - f1: 1.1383 - val_loss: 2.1559 - val_f1: 2.6576\n",
      "Epoch 75/100\n",
      "13351/13351 - 4s - loss: 0.0324 - f1: 1.1241 - val_loss: 2.1655 - val_f1: 2.7183\n",
      "Epoch 76/100\n",
      "13351/13351 - 4s - loss: 0.0313 - f1: 1.1172 - val_loss: 2.1896 - val_f1: 2.5927\n",
      "Epoch 77/100\n",
      "13351/13351 - 4s - loss: 0.0302 - f1: 1.1126 - val_loss: 2.2075 - val_f1: 2.6517\n",
      "Epoch 78/100\n",
      "13351/13351 - 4s - loss: 0.0290 - f1: 1.1021 - val_loss: 2.2285 - val_f1: 2.5909\n",
      "Epoch 79/100\n",
      "13351/13351 - 4s - loss: 0.0286 - f1: 1.0998 - val_loss: 2.2447 - val_f1: 2.5962\n",
      "Epoch 80/100\n",
      "13351/13351 - 4s - loss: 0.0279 - f1: 1.0963 - val_loss: 2.2700 - val_f1: 2.5450\n",
      "Epoch 81/100\n",
      "13351/13351 - 4s - loss: 0.0270 - f1: 1.0943 - val_loss: 2.3045 - val_f1: 2.4465\n",
      "Epoch 82/100\n",
      "13351/13351 - 4s - loss: 0.0262 - f1: 1.0876 - val_loss: 2.3247 - val_f1: 2.4525\n",
      "Epoch 83/100\n",
      "13351/13351 - 4s - loss: 0.0256 - f1: 1.0800 - val_loss: 2.3409 - val_f1: 2.4211\n",
      "Epoch 84/100\n",
      "13351/13351 - 4s - loss: 0.0253 - f1: 1.0791 - val_loss: 2.3494 - val_f1: 2.5219\n",
      "Epoch 85/100\n",
      "13351/13351 - 4s - loss: 0.0244 - f1: 1.0802 - val_loss: 2.3874 - val_f1: 2.3875\n",
      "Epoch 86/100\n",
      "13351/13351 - 4s - loss: 0.0240 - f1: 1.0680 - val_loss: 2.3820 - val_f1: 2.5389\n",
      "Epoch 87/100\n",
      "13351/13351 - 4s - loss: 0.0240 - f1: 1.0750 - val_loss: 2.4212 - val_f1: 2.3960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "13351/13351 - 4s - loss: 0.0239 - f1: 1.0805 - val_loss: 2.4218 - val_f1: 2.4287\n",
      "Epoch 89/100\n",
      "13351/13351 - 4s - loss: 0.0236 - f1: 1.0664 - val_loss: 2.4411 - val_f1: 2.4567\n",
      "Epoch 90/100\n",
      "13351/13351 - 4s - loss: 0.0222 - f1: 1.0677 - val_loss: 2.4711 - val_f1: 2.4032\n",
      "Epoch 91/100\n",
      "13351/13351 - 4s - loss: 0.0218 - f1: 1.0666 - val_loss: 2.4684 - val_f1: 2.3950\n",
      "Epoch 92/100\n",
      "13351/13351 - 4s - loss: 0.0220 - f1: 1.0669 - val_loss: 2.4901 - val_f1: 2.4078\n",
      "Epoch 93/100\n",
      "13351/13351 - 4s - loss: 0.0222 - f1: 1.0662 - val_loss: 2.5390 - val_f1: 2.3558\n",
      "Epoch 94/100\n",
      "13351/13351 - 4s - loss: 0.0217 - f1: 1.0624 - val_loss: 2.5301 - val_f1: 2.3990\n",
      "Epoch 95/100\n",
      "13351/13351 - 4s - loss: 0.0214 - f1: 1.0648 - val_loss: 2.5536 - val_f1: 2.3446\n",
      "Epoch 96/100\n",
      "13351/13351 - 4s - loss: 0.0216 - f1: 1.0631 - val_loss: 2.5652 - val_f1: 2.3247\n",
      "Epoch 97/100\n",
      "13351/13351 - 4s - loss: 0.0210 - f1: 1.0637 - val_loss: 2.5876 - val_f1: 2.2460\n",
      "Epoch 98/100\n",
      "13351/13351 - 4s - loss: 0.0208 - f1: 1.0573 - val_loss: 2.6135 - val_f1: 2.2727\n",
      "Epoch 99/100\n",
      "13351/13351 - 4s - loss: 0.0212 - f1: 1.0648 - val_loss: 2.6108 - val_f1: 2.2958\n",
      "Epoch 100/100\n",
      "13351/13351 - 4s - loss: 0.0206 - f1: 1.0596 - val_loss: 2.6294 - val_f1: 2.2616\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_padded, training_classes_seq, epochs=num_epochs, validation_data=(test_padded, test_classes_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5709/5709 [==============================] - 0s 42us/sample\n",
      "|Class Label                            |Pre |Rec |F1\n",
      "|--- |--- |--- |---\n",
      "|attualit_                               |0.21|0.26|0.23\n",
      "|attualit__ambiente                      |0.53|0.55|0.54\n",
      "|attualit__media                         |0.44|0.49|0.46\n",
      "|attualit__politica                      |0.56|0.57|0.56\n",
      "|attualit__tech                          |0.34|0.25|0.29\n",
      "|economia_business                       |0.36|0.42|0.39\n",
      "|economia_finanza                        |0.66|0.63|0.64\n",
      "|economia_lavoro                         |0.74|0.59|0.66\n",
      "|economia_startup                        |0.73|0.64|0.68\n",
      "|gadget_accessori                        |0.45|0.42|0.43\n",
      "|gadget_audio_e_tv                       |0.71|0.79|0.74\n",
      "|gadget_computer                         |0.73|0.62|0.67\n",
      "|gadget_elettrodomestici                 |0.57|0.47|0.51\n",
      "|gadget_foto_e_video                     |0.69|0.74|0.71\n",
      "|gadget_motori                           |0.75|0.82|0.78\n",
      "|gadget_outdoor                          |0.57|0.61|0.59\n",
      "|gadget_videogiochi                      |0.84|0.86|0.85\n",
      "|internet_regole                         |0.53|0.27|0.36\n",
      "|internet_social_network                 |0.60|0.71|0.65\n",
      "|internet_tlc                            |0.53|0.56|0.54\n",
      "|internet_web                            |0.47|0.41|0.44\n",
      "|lifestyle_design                        |0.53|0.56|0.55\n",
      "|lifestyle_food                          |0.71|0.74|0.73\n",
      "|lifestyle_mobilit_                      |0.79|0.66|0.72\n",
      "|lifestyle_salute                        |0.45|0.37|0.41\n",
      "|lifestyle_viaggi                        |0.55|0.46|0.50\n",
      "|lol                                     |0.35|0.65|0.46\n",
      "|mobile_app                              |0.59|0.58|0.59\n",
      "|mobile_smartphone                       |0.82|0.78|0.80\n",
      "|mobile_tablet                           |0.80|0.80|0.80\n",
      "|play_cinema                             |0.76|0.84|0.80\n",
      "|play_cultura                            |0.32|0.32|0.32\n",
      "|play_fumetti                            |0.84|0.83|0.84\n",
      "|play_libri                              |0.74|0.74|0.74\n",
      "|play_musica                             |0.75|0.71|0.73\n",
      "|play_tv                                 |0.77|0.73|0.75\n",
      "|scienza                                 |0.46|0.34|0.39\n",
      "|scienza_biotech                         |0.40|0.28|0.33\n",
      "|scienza_ecologia                        |0.47|0.60|0.52\n",
      "|scienza_lab                             |0.40|0.37|0.39\n",
      "|scienza_medicina                        |0.64|0.57|0.60\n",
      "|scienza_spazio                          |0.79|0.91|0.85\n",
      "\n",
      "|Average Type |Prec |Rec |F1\n",
      "|--- |--- |--- |---\n",
      "|micro|0.59|0.59|0.59\n",
      "|macro|0.59|0.58|0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "classes_probabilties = model.predict(test_padded, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(classes_probabilties, axis=1).tolist()\n",
    "expected = flatten(test_classes_seq)\n",
    "precision_scores = metrics.precision_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "recall_scores = metrics.recall_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "f1_scores = metrics.f1_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "precion_recall_f1_scores = list(zip(precision_scores, recall_scores, f1_scores))\n",
    "print('|Class Label'.ljust(40, ' ') + '|Pre |Rec |F1')\n",
    "print('|--- |--- |--- |---')\n",
    "for index, precision_recall_f1 in enumerate(precion_recall_f1_scores):\n",
    "    classLabel = classes_by_index[index + 1]\n",
    "    print('|%s|%.2f|%.2f|%.2f' % (classLabel.ljust(40, ' '), precision_recall_f1[0], precision_recall_f1[1], precision_recall_f1[2]))\n",
    "\n",
    "precision_score_micro_averaged = metrics.precision_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "precision_score_macro_averaged = metrics.precision_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "recall_score_micro_averaged = metrics.recall_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "recall_score_macro_averaged = metrics.recall_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "f1_score_micro_averaged = metrics.f1_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "f1_score_macro_averaged = metrics.f1_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "print()\n",
    "print('|Average Type |Prec |Rec |F1')\n",
    "print('|--- |--- |--- |---')\n",
    "print('|micro|%.2f|%.2f|%.2f' % (precision_score_micro_averaged, recall_score_micro_averaged, f1_score_micro_averaged))\n",
    "print('|macro|%.2f|%.2f|%.2f' % (precision_score_macro_averaged, recall_score_macro_averaged, f1_score_macro_averaged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
