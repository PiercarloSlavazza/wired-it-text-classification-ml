{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook:\n",
    "\n",
    "```\n",
    "pip install tqdm\n",
    "pip install pandas\n",
    "pip install ipywidgets\n",
    "jupyter_http_over_ws\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```\n",
    "\n",
    "And then restart Jupypter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corpus_base_dir = 'C:\\\\Users\\\\piercarlo\\\\Documents\\\\workspace\\\\personal\\\\wired-it-text-classification-ml\\\\corpora\\\\wired_it_20190821_segmented_preprocessed'\n",
    "training_dir = os.path.join(corpus_base_dir, 'training')\n",
    "test_dir = os.path.join(corpus_base_dir, 'test')\n",
    "classes = ['attualit_', 'attualit__ambiente', 'attualit__media', 'attualit__politica', 'attualit__tech', 'economia_business', 'economia_finanza', 'economia_lavoro', 'economia_startup', 'gadget_accessori', 'gadget_audio_e_tv', 'gadget_computer', 'gadget_elettrodomestici', 'gadget_foto_e_video', 'gadget_motori', 'gadget_outdoor', 'gadget_videogiochi', 'internet_regole', 'internet_social_network', 'internet_tlc', 'internet_web', 'lifestyle_design', 'lifestyle_food', 'lifestyle_mobilit_', 'lifestyle_salute', 'lifestyle_viaggi', 'lol', 'mobile_app', 'mobile_smartphone', 'mobile_tablet', 'play_cinema', 'play_cultura', 'play_fumetti', 'play_libri', 'play_musica', 'play_tv', 'scienza', 'scienza_biotech', 'scienza_ecologia', 'scienza_lab', 'scienza_medicina', 'scienza_spazio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file_to_lines(file_path):\n",
    "  with open(file_path, 'r', encoding=\"utf8\") as file:\n",
    "    return [line.replace('\\n', '') for line in file.readlines()]\n",
    "def list_text_files(folder):\n",
    "  return [os.path.join(folder, file_name) for file_name in os.listdir(folder) if file_name.endswith('.txt')]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "load_class_text_pairs = lambda folder: map(lambda classLabel: map(lambda file_name: (classLabel, read_file_to_lines(file_name)), list_text_files(os.path.join(folder, classLabel))) , classes)\n",
    "training_classes, training_texts = zip(*flatten(list(load_class_text_pairs(training_dir))))\n",
    "test_classes, test_texts = zip(*flatten(list(load_class_text_pairs(test_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize classes \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "classes_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "classes_tokenizer.fit_on_texts(classes)\n",
    "classes_word_index = classes_tokenizer.word_index\n",
    "tokenized_training_classes = flatten(classes_tokenizer.texts_to_sequences(training_classes))\n",
    "tokenized_test_classes = flatten(classes_tokenizer.texts_to_sequences(test_classes))\n",
    "\n",
    "classes_by_index = dict([(index, key) for (key, index) in classes_word_index.items()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BEWARE!*\n",
    "\n",
    "We assume that the Bert Server will encode whole lines, so its `-pooling_strategy` msut be set to something different from `NONE` - e.g. `REDUCE_MEAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient(ip='127.0.0.1', port=5555, port_out=5556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LINES_PER_TEXT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode_texts_lines(texts_lines, data_set_name, max_lines_to_encode):\n",
    "    print(\"start|bert encoding|{}|max lines|{}|at|{}\".format(data_set_name, max_lines_to_encode, datetime.datetime.now()))\n",
    "    texts_count = len(texts_lines)\n",
    "    texts_lines_encoded = []\n",
    "    # We pass the lines per each document because otherwise the server is prone to crash\n",
    "    with tqdm(total=texts_count) as progress_bar:\n",
    "        for index in range(texts_count):\n",
    "            text_lines = texts_lines[index]\n",
    "            \n",
    "            lines_to_encode_up_to_max = text_lines[:max_lines_to_encode] if len(text_lines) > 0 else ['dummy']\n",
    "            \n",
    "            missing_lines_to_fill_maximum = max_lines_to_encode - len(lines_to_encode_up_to_max)\n",
    "            \n",
    "            padded_lines_to_encode = lines_to_encode_up_to_max + ['dummy'] * missing_lines_to_fill_maximum\n",
    "            \n",
    "            padded_lines_encoded = bc.encode(padded_lines_to_encode)\n",
    "            \n",
    "            texts_lines_encoded.append(padded_lines_encoded)\n",
    "            \n",
    "            progress_bar.update(1)\n",
    "        return np.array(texts_lines_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_texts_lines_encoded = bert_encode_texts_lines(training_texts, 'training', MAX_LINES_PER_TEXT)\n",
    "test_texts_lines_encoded = bert_encode_texts_lines(test_texts, 'test', MAX_LINES_PER_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GlobalAveragePooling1D(input_shape=(training_texts_lines_encoded.shape[1:])),\n",
    "    tf.keras.layers.Dense(len(classes) + 1, activation='softmax')\n",
    "])\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(training_texts_lines_encoded,\n",
    "                    tokenized_training_classes,\n",
    "                    epochs=60, \n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(test_texts_lines_encoded, tokenized_test_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "classes_probabilties = model.predict(test_texts_lines_encoded, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(classes_probabilties, axis=1).tolist()\n",
    "expected = tokenized_test_classes\n",
    "precision_scores = metrics.precision_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "recall_scores = metrics.recall_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "f1_scores = metrics.f1_score(expected, predicted, labels=np.unique(expected), average=None)\n",
    "precion_recall_f1_scores = list(zip(precision_scores, recall_scores, f1_scores))\n",
    "print('|Class Label'.ljust(40, ' ') + '|Pre |Rec |F1')\n",
    "print('|--- |--- |--- |---')\n",
    "for index, precision_recall_f1 in enumerate(precion_recall_f1_scores):\n",
    "    classLabel = classes_by_index[index + 1]\n",
    "    print('|%s|%.2f|%.2f|%.2f' % (classLabel.ljust(40, ' '), precision_recall_f1[0], precision_recall_f1[1], precision_recall_f1[2]))\n",
    "\n",
    "precision_score_micro_averaged = metrics.precision_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "precision_score_macro_averaged = metrics.precision_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "recall_score_micro_averaged = metrics.recall_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "recall_score_macro_averaged = metrics.recall_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "f1_score_micro_averaged = metrics.f1_score(expected, predicted, labels=np.unique(expected), average='micro')\n",
    "f1_score_macro_averaged = metrics.f1_score(expected, predicted, labels=np.unique(expected), average='macro')\n",
    "\n",
    "print()\n",
    "print('|Average Type |Prec |Rec |F1')\n",
    "print('|--- |--- |--- |---')\n",
    "print('|micro|%.2f|%.2f|%.2f' % (precision_score_micro_averaged, recall_score_micro_averaged, f1_score_micro_averaged))\n",
    "print('|macro|%.2f|%.2f|%.2f' % (precision_score_macro_averaged, recall_score_macro_averaged, f1_score_macro_averaged))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
